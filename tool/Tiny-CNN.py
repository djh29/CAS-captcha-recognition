import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms
import os
import cv2
import numpy as np

def remove_black_lines(image_path):
    # # è¯»å–å›¾åƒ
    img = cv2.imread(image_path)
    # # åˆ›å»ºé»‘è‰²åƒç´ æ©è†œï¼ˆRGBéƒ½å°äº10ï¼‰
    mask = np.all(img < [50, 50, 50], axis=2).astype(np.uint8) * 255
    # # ä½¿ç”¨å›¾åƒä¿®å¤å»é™¤å¹²æ‰°çº¿
    result = cv2.inpaint(img, mask, inpaintRadius=2, flags=cv2.INPAINT_TELEA)

    return result

# 1. æ•°æ®é›†ç±»å®šä¹‰
class CaptchaDataset(Dataset):
    def __init__(self, data_dir, transform=None):
        self.data_dir = data_dir
        self.transform = transform
        self.filenames = [f for f in os.listdir(data_dir) if f.endswith(('.jpg','.png'))]
        
        # åˆ›å»ºå­—ç¬¦åˆ°ç´¢å¼•çš„æ˜ å°„
        self.char2idx = {chr(ord('a')+i): i for i in range(26)}
        for i in range(10):
            self.char2idx[str(i)] = i + 26

    def __len__(self):
        return len(self.filenames)

    def __getitem__(self, idx):
        img_path = os.path.join(self.data_dir, self.filenames[idx])
        # å»é™¤å¹²æ‰°çº¿å¹¶è½¬ä¸ºç°åº¦å›¾
        img = remove_black_lines(img_path)
        # img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        
        # è½¬æ¢å¼ é‡
        if self.transform:
            img = self.transform(img)
        
        # ä»æ–‡ä»¶åè·å–æ ‡ç­¾
        label_str = self.filenames[idx].split('_')[0]
        label = [self.char2idx[c] for c in label_str]
        return img, torch.tensor(label)

# 2. è½»é‡CNNæ¨¡å‹ï¼ˆ<1MBï¼‰
class TinyCNN(nn.Module):
    def __init__(self, num_chars=4, num_classes=36):
        super(TinyCNN, self).__init__()
        self.features = nn.Sequential(
            # è¾“å…¥: 1x32x90
            nn.Conv2d(3, 8, 3, padding=1),  # 16x32x90
            nn.BatchNorm2d(8),
            nn.ReLU(),
            nn.MaxPool2d(2),  # 16x16x45
            
            nn.Conv2d(8, 16, 3, padding=1),  # 32x16x45
            nn.BatchNorm2d(16),
            nn.ReLU(),
            nn.MaxPool2d(2),  # 32x8x22
            
            nn.Conv2d(16, 32, 3, padding=1),  # 64x8x22
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.AdaptiveAvgPool2d((4, 11))  # 64x4x11
        )
        
        self.classifier = nn.Sequential(
            nn.Linear(32*4*11, 128),
            nn.Dropout(0.3),
            nn.LayerNorm(128),  # ğŸŒŸ å±‚å½’ä¸€åŒ–
            nn.Linear(128, num_chars*num_classes)
        )
        self.num_chars = num_chars
        self.num_classes = num_classes

    def forward(self, x):
        x = self.features(x)
        x = torch.flatten(x, 1)
        x = self.classifier(x)
        return x.view(-1, self.num_chars, self.num_classes)

# 4. è®­ç»ƒå¾ªç¯
def train(model, train_dataloader, val_dataloader, epochs=300, save_threshold=0.9985):
    model.train()  # è®¾ç½®æ¨¡å‹ä¸ºè®­ç»ƒæ¨¡å¼
    criterion = nn.CrossEntropyLoss()  # å®šä¹‰æŸå¤±å‡½æ•°
    optimizer = optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)  # å®šä¹‰ä¼˜åŒ–å™¨
    scheduler = torch.optim.lr_scheduler.OneCycleLR(
        optimizer, max_lr=3e-3, steps_per_epoch=len(train_dataloader), epochs=epochs
    )  # å®šä¹‰å­¦ä¹ ç‡è°ƒåº¦å™¨

    for epoch in range(epochs):
        total_loss = 0
        correct = 0
        total = 0

        for inputs, labels in train_dataloader:
            optimizer.zero_grad()  # æ¸…ç©ºæ¢¯åº¦
            outputs = model(inputs)  # å‰å‘ä¼ æ’­

            # è®¡ç®—å››ä¸ªå­—ç¬¦çš„æŸå¤±
            loss = sum(criterion(outputs[:, i, :], labels[:, i]) for i in range(4))
            loss.backward()  # åå‘ä¼ æ’­
            optimizer.step()  # æ›´æ–°å‚æ•°
            scheduler.step()  # æ›´æ–°å­¦ä¹ ç‡

            # è®¡ç®—å‡†ç¡®ç‡
            _, predicted = torch.max(outputs, 2)
            correct += (predicted == labels).all(1).sum().item()
            total += labels.size(0)
            total_loss += loss.item()

        # æ‰“å°è®­ç»ƒä¿¡æ¯
        train_loss = total_loss / total
        train_acc = correct / total
        print(f"Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss:.6f}, Train Acc: {train_acc:.4%}, LR: {optimizer.param_groups[0]['lr']:.6f}")

        # éªŒè¯æ¨¡å‹
        val_loss, val_acc = validate(model, val_dataloader, criterion)
        print(f"Epoch {epoch + 1}/{epochs}, Val Loss: {val_loss:.6f}, Val Acc: {val_acc:.4%}")

        # ä¿å­˜æ¨¡å‹
        if val_acc > save_threshold:
            torch.save(model.state_dict(), f"{val_acc:.6f}_light_captcha_model.pth")
            print(f"Model saved with validation accuracy: {val_acc:.4%}")


# 5. éªŒè¯å‡½æ•°
def validate(model, dataloader, criterion):
    model.eval()  # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼
    total_loss = 0
    correct = 0
    total = 0

    with torch.no_grad():  # å…³é—­æ¢¯åº¦è®¡ç®—
        for inputs, labels in dataloader:
            outputs = model(inputs)  # å‰å‘ä¼ æ’­

            # è®¡ç®—æŸå¤±
            loss = sum(criterion(outputs[:, i, :], labels[:, i]) for i in range(4))
            total_loss += loss.item()

            # è®¡ç®—å‡†ç¡®ç‡
            _, predicted = torch.max(outputs, 2)
            correct += (predicted == labels).all(1).sum().item()
            total += labels.size(0)

    val_loss = total_loss / total
    val_acc = correct / total
    return val_loss, val_acc

if __name__ == "__main__":
# è®¡ç®—å‚æ•°é‡
model = TinyCNN()
print("æ¨¡å‹å‚æ•°é‡ï¼š", sum(p.numel() for p in model.parameters()))  # çº¦802.6KB

# 3. è®­ç»ƒé…ç½®
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])
])

train_dataset = CaptchaDataset('path to your train data', transform=transform)
train_dataloader = DataLoader(train_dataset, batch_size=256, shuffle=True)
val_dataset = CaptchaDataset('path to your validate data', transform=transform)
val_dataloader = DataLoader(val_dataset, batch_size=256, shuffle=True)

# å¯åŠ¨è®­ç»ƒ
train(model,train_dataloader, val_dataloader, epochs=300, save_threshold=0.9985)

#æŠŠæ¨¡å‹è½¬ä¸ºonnxæ¨¡å‹
def convert_to_onnx(model, output_path):
    dummy_input = torch.randn(1, 3, 32, 90)
    torch.onnx.export(
        model, 
        dummy_input, 
        output_path,
        input_names=['input'], 
        output_names=['output'],
        dynamic_axes={'input': {0: 'batch_size'}, 
                      'output': {0: 'batch_size'}}
    )

